Title,Assigned Topic,Topic Keywords
Security PSA: huggingface models are code. not just data.,Topic 1,"model, code, training, llm, data, question, finetuning, set, best, experience"
Security isolation and risk of malware,Topic 0,"v, gpt, ai, model, test, security, gemini, using, uncensored, showdown"
"FACT SHEET: President Biden Issues Executive Order on Safe, Secure, and Trustworthy Artificial Intelligence | The White House",Topic 8,"local, llm, order, executive, running, v, wizard, privacy, opensource, fully"
"Ok, I’m just curious of the security risks?",Topic 0,"v, gpt, ai, model, test, security, gemini, using, uncensored, showdown"
Docker vs. native security,Topic 0,"v, gpt, ai, model, test, security, gemini, using, uncensored, showdown"
Is Taiwan an independent country? Deepseek LLM: Msg withdrawn due to security!,Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
Is there a Local LLM security primer?,Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
"The White House - Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence",Topic 8,"local, llm, order, executive, running, v, wizard, privacy, opensource, fully"
"How Can I Optimize Execution Times for a Secure, Self-Hosted Llama2-Chat 7-B Model Deployed with Truss and Kubernetes on a Tesla T4 GPU",Topic 1,"model, code, training, llm, data, question, finetuning, set, best, experience"
"Mark Zuckerberg with a fantastic, insightful reply in a podcast on why he really believes in open-source models.",Topic 2,"llm, model, llama, local, mistral, etc, use, cloud, generative, language"
Wanna benchmark your model's cognitive behavioral reasoning capabilities for Cybersecurity?,Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
Biden Executive Order regulates VERY large models,Topic 1,"model, code, training, llm, data, question, finetuning, set, best, experience"
Preparedness - by OpenAI,Topic 1,"model, code, training, llm, data, question, finetuning, set, best, experience"
"Who needs ""Galaxy AI"" or ""Gemini"" when real models run fine on phones?",Topic 4,"ai, llm, running, data, comparing, llama, gpus, need, privacy, fine"
Automatic hallucination detection using inconsistency scoring,Topic 9,"llm, run, model, using, time, locally, local, gpu, prompt, ram"
Looking for the best cost/price mini(?)-pc for a local llm,Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
Whats the best way to isolate an Llm?,Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
"This is why i hate Gemini, just asked to replace 10.0.0.21 to localost",Topic 2,"llm, model, llama, local, mistral, etc, use, cloud, generative, language"
Could AI break all our encryption?,Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
Is there a business in installing Local LLMs?,Topic 9,"llm, run, model, using, time, locally, local, gpu, prompt, ram"
"Blind Chat - OS privacy-first ChatGPT alternative, running fully in-browser",Topic 4,"ai, llm, running, data, comparing, llama, gpus, need, privacy, fine"
Why we need to run AI on our own computers.,Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
Section 4.6 of the executive order is what we need to know about.,Topic 8,"local, llm, order, executive, running, v, wizard, privacy, opensource, fully"
TCO Calculator to compare cost of local deployment vs SaaS solutions,Topic 7,"llm, local, ui, better, v, docker, rag, ollama, web, two"
Local Phi-1.5 running fully in browser for privacy with open-source project BlindChat,Topic 8,"local, llm, order, executive, running, v, wizard, privacy, opensource, fully"
flan T5-Large just gives the context as the response,Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
"With half a TB of ram and 8x 1080s, what’s the best unsafe coding model?",Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
Moore Threads MTT S4000 48GB AI GPU: with MTLink and zero-cost NVIDIA CUDA framework,Topic 4,"ai, llm, running, data, comparing, llama, gpus, need, privacy, fine"
How Do We Evaluate/Test Open Source Models for Cyber-Safety?,Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
Intro to Large Language Models | Andrew Karpathy | Summary,Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
Locally-hosted Offline LLM for past threat intelligence usage,Topic 9,"llm, run, model, using, time, locally, local, gpu, prompt, ram"
LLM trained on code memorizes 8% of the training set and could expose code used for training,Topic 1,"model, code, training, llm, data, question, finetuning, set, best, experience"
"CodeLLama 70B pontificates on ethics where 13B and 7B ""just do it""",Topic 0,"v, gpt, ai, model, test, security, gemini, using, uncensored, showdown"
What's the largest existing LLM that an individual can feasibly run privately?,Topic 9,"llm, run, model, using, time, locally, local, gpu, prompt, ram"
Why LocalLLaMa when GPT-4 exists?,Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
🦙 How To: Build Chatbot that knows your company's documents,Topic 9,"llm, run, model, using, time, locally, local, gpu, prompt, ram"
The Dark Side of AI Censorship,Topic 4,"ai, llm, running, data, comparing, llama, gpus, need, privacy, fine"
"🚀 Completely Local RAG with Ollama Web UI, in Two Docker Commands!",Topic 7,"llm, local, ui, better, v, docker, rag, ollama, web, two"
"Please enlighten me, why are people building LLM Twitter bots?",Topic 2,"llm, model, llama, local, mistral, etc, use, cloud, generative, language"
Is llama actually more expensive than GPT,Topic 4,"ai, llm, running, data, comparing, llama, gpus, need, privacy, fine"
Ai for code documentation errors?,Topic 4,"ai, llm, running, data, comparing, llama, gpus, need, privacy, fine"
Build my own version of HackerGPT,Topic 0,"v, gpt, ai, model, test, security, gemini, using, uncensored, showdown"
"Local LLM to learn, explore and use for commercial purpose",Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
Encourage Your Workplace to Host its Own LLMs,Topic 9,"llm, run, model, using, time, locally, local, gpu, prompt, ram"
Llama 2 70b how to run,Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
M1/M2/M3: increase VRAM allocation with `sudo sysctl iogpu.wired_limit_mb=12345` (i.e. amount in mb to allocate),Topic 2,"llm, model, llama, local, mistral, etc, use, cloud, generative, language"
"Good, cheap cloud providers for llm work",Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
Is renting GPUs only possible because we still don't have a killer open source model?,Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
Looking for Python script to deploy custom LLM in Azure,Topic 9,"llm, run, model, using, time, locally, local, gpu, prompt, ram"
How do you compare 100s of documents with a local LLM?,Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
Is there a cloud gpu I can rent on an as needed basis?,Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
Estimated time and effort to set up a local LLM at my company?,Topic 9,"llm, run, model, using, time, locally, local, gpu, prompt, ram"
Need a scalable solution for running LLMs,Topic 4,"ai, llm, running, data, comparing, llama, gpus, need, privacy, fine"
"Neurochat: new Open-Source GUI for LLama.cpp, ChatGPT and free AI services",Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
A question about vision models (LLaVA),Topic 1,"model, code, training, llm, data, question, finetuning, set, best, experience"
LLM for audit logs,Topic 9,"llm, run, model, using, time, locally, local, gpu, prompt, ram"
PHIND V7: Red Flags,Topic 2,"llm, model, llama, local, mistral, etc, use, cloud, generative, language"
Is the A6000 GPU slow for the 7B model on Runpod?,Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
Fine tuning embeddings,Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
LLM as a Service API,Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
Any safety advice for a newbie?,Topic 4,"ai, llm, running, data, comparing, llama, gpus, need, privacy, fine"
Has anyone developed a reliable SQL agent? ,Topic 0,"v, gpt, ai, model, test, security, gemini, using, uncensored, showdown"
Alright then keep your secrets,Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
Assessing llms for code generation.,Topic 1,"model, code, training, llm, data, question, finetuning, set, best, experience"
Experience report: Phi2 context extension works well for summaries,Topic 1,"model, code, training, llm, data, question, finetuning, set, best, experience"
"Let's say I have $6,000-8,000 for a new computer to run local llamas- what should I get?",Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
"future of foss llm's? foundational model = framework, fine tuning data = library",Topic 4,"ai, llm, running, data, comparing, llama, gpus, need, privacy, fine"
Method to block possible internet traffic from LLaMA on MacOS,Topic 2,"llm, model, llama, local, mistral, etc, use, cloud, generative, language"
Waiting times for A100 hw?,Topic 9,"llm, run, model, using, time, locally, local, gpu, prompt, ram"
How do you get LLaMA to stop?,Topic 1,"model, code, training, llm, data, question, finetuning, set, best, experience"
Google Cloud partners with Mistral AI on generative language models,Topic 2,"llm, model, llama, local, mistral, etc, use, cloud, generative, language"
LVE Project: First Open Source Repository of LLM Vulnerabilities,Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
Generative Agents now open-sourced.,Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
Newb question about using llama for private data.,Topic 0,"v, gpt, ai, model, test, security, gemini, using, uncensored, showdown"
Several newb questions,Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
Evaluate Your Own LLM using PromptBench,Topic 9,"llm, run, model, using, time, locally, local, gpu, prompt, ram"
Anyway to save your cloud GPU fine-tuned models to your local storage?,Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
Plot_BOT V3 13b GPTQ - a FULLY UNCENSORED plot crafting and writing assistant,Topic 1,"model, code, training, llm, data, question, finetuning, set, best, experience"
"New benchmark by Stanford: HELM lite v1.0.0 including Narrative, Math, Legal, Medicine, Translation tasks",Topic 1,"model, code, training, llm, data, question, finetuning, set, best, experience"
"surprising enough apple doing some open sourcing stuff in Ai, did any one test apple ferrate till ?now?",Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
Running local LLM for info retrieval of technical documents,Topic 8,"local, llm, order, executive, running, v, wizard, privacy, opensource, fully"
Model suggestions for coding + workflow?,Topic 1,"model, code, training, llm, data, question, finetuning, set, best, experience"
Does labeling datasets stored in a Vector DB make sense?,Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
"Guide: build llama.cpp on windows with AMD GPUs, and using ROCm",Topic 4,"ai, llm, running, data, comparing, llama, gpus, need, privacy, fine"
OpenChat 3.2 SUPER is Here!,Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
Quick overview of price/preformance for text generation on different GPUs,Topic 7,"llm, local, ui, better, v, docker, rag, ollama, web, two"
[Demo App] Can we have an oss always-on assistant in 2024?,Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
Generating JSON with self hosted LLM,Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
The Milgram experiment as prompt injection in humans.,Topic 2,"llm, model, llama, local, mistral, etc, use, cloud, generative, language"
Advantage of Local vs GPT4 for use case? Generating text in specific style based on examples,Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
Open Source LLM Crushes Rivals in GSAT English Test Showdown!,Topic 2,"llm, model, llama, local, mistral, etc, use, cloud, generative, language"
"Zephyr comes up with an original, impressive joke.",Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
Starling won't stop spitting training data!,Topic 1,"model, code, training, llm, data, question, finetuning, set, best, experience"
I wish there was a market for buying access to proprietary LLMs to run locally,Topic 9,"llm, run, model, using, time, locally, local, gpu, prompt, ram"
How do I run Stable Diffusion and LLMs from my PC on my mobile device? Offline and private ways?,Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
End to End Local Mistral-7b Finetune for AI Classics Assistant on Mac M2 Max,Topic 4,"ai, llm, running, data, comparing, llama, gpus, need, privacy, fine"
Open Source Wishlist,Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
(New Model) Rift Coder 7B. Python & TypeScript Fine-Tuned Code Llama for IDE Use,Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
LexPodLM-13B,Topic 1,"model, code, training, llm, data, question, finetuning, set, best, experience"
"First timer building a new (to me) rig for LLM inference, fine-tuning, etc. Flame my choices, recommend me a different way, and any ideas on benchmarking 2x P40 vs 2x P100?",Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
Train a local LLM on my files for use as a general-purpose chatbot,Topic 8,"local, llm, order, executive, running, v, wizard, privacy, opensource, fully"
Persistent cloud computing setup to run different LLM models.,Topic 9,"llm, run, model, using, time, locally, local, gpu, prompt, ram"
Fireworks.ai Mixtral vs GPT-4 turbo,Topic 0,"v, gpt, ai, model, test, security, gemini, using, uncensored, showdown"
Some Lessons Learned from Building a Fine Tuned Model + RAG Question Answering App,Topic 0,"v, gpt, ai, model, test, security, gemini, using, uncensored, showdown"
Minimal docker setup for CPU based oobabooga text gen,Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
Using GPU's on a Mac M2 Max via MLX: Update on Training Data Generation+Instruct+Fine-Tune Locally,Topic 1,"model, code, training, llm, data, question, finetuning, set, best, experience"
Here's a Docker image for 24GB GPU owners to run exui/exllamav2 for 34B models (and more).,Topic 9,"llm, run, model, using, time, locally, local, gpu, prompt, ram"
Mark Zuckerberg on upcoming LLaMA v2,Topic 2,"llm, model, llama, local, mistral, etc, use, cloud, generative, language"
"AI Showdown: WizardLM Uncensored vs. Gpt4-x-vicuna, GPT-4 as the judge (test in comments)",Topic 0,"v, gpt, ai, model, test, security, gemini, using, uncensored, showdown"
"AI Showdown: WizardLM 30b VS Guanaco 33b, GPT-4 as the judge (test in comments)",Topic 0,"v, gpt, ai, model, test, security, gemini, using, uncensored, showdown"
"Comparing Image/Chart/Illustration Descriptions generated by GPT-4V, LLaVa, Owen-VL for RAG Pipelines",Topic 4,"ai, llm, running, data, comparing, llama, gpus, need, privacy, fine"
"AI Showdown: Wizard Vicuna Uncensored VS Wizard Mega, GPT-4 as the judge (test in comments)",Topic 0,"v, gpt, ai, model, test, security, gemini, using, uncensored, showdown"
"Adding keywords related to topic to LLM context improves performance, here's my prompt to generate them and some keywords for being a machine-learning engineer.",Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
WizardLM 7B vs Vicuan 13B (vs gpt-3.5-turbo) Comparison.,Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
"Quick hardware comparison Ryzen 5700X, RTX 3090, Mac Studio M1",Topic 2,"llm, model, llama, local, mistral, etc, use, cloud, generative, language"
Comparing StableLM Tuned 7B and Vicuna 7B,Topic 4,"ai, llm, running, data, comparing, llama, gpus, need, privacy, fine"
🐺🐦‍⬛ LLM Prompt Format Comparison/Test: Mixtral 8x7B Instruct with **17** different instruct templates,Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
Dolphin's consistency reduced my question to absurdity -.-,Topic 7,"llm, local, ui, better, v, docker, rag, ollama, web, two"
Question about data privacy,Topic 4,"ai, llm, running, data, comparing, llama, gpus, need, privacy, fine"
"I have created a Chrome extension to chatGPT with the page. It uses locallama, is free with 100% privacy, and open open-source",Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
Llama on Azure endpoint online and privacy,Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
can remote llms achieve zero-knowledge privacy?,Topic 9,"llm, run, model, using, time, locally, local, gpu, prompt, ram"
Question about privacy on local models running on LM Studio,Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
"Blind Chat - OS privacy-first ChatGPT alternative, running fully in-browser",Topic 4,"ai, llm, running, data, comparing, llama, gpus, need, privacy, fine"
Local Phi-1.5 running fully in browser for privacy with open-source project BlindChat,Topic 8,"local, llm, order, executive, running, v, wizard, privacy, opensource, fully"
"LLM cross-session privacy leak: “A Flaw in Millions of Apple, AMD, and Qualcomm GPUs Could Expose AI Data”",Topic 4,"ai, llm, running, data, comparing, llama, gpus, need, privacy, fine"
"What is your motive for running open-source models, instead of just using a ready-made solution like GPT-4?",Topic 0,"v, gpt, ai, model, test, security, gemini, using, uncensored, showdown"
Alright then keep your secrets,Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
Is there really no way you can run 70b models without having a very fast GPU or a lot of ram?,Topic 9,"llm, run, model, using, time, locally, local, gpu, prompt, ram"
What's the most cost-efficient setup for trying out LLM (mistral / llama2 etc) finetuning and inference,Topic 4,"ai, llm, running, data, comparing, llama, gpus, need, privacy, fine"
Why are you guys running local LLMs?,Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
GitHub Copilot vs CodeLlama & Co for Code productivity,Topic 8,"local, llm, order, executive, running, v, wizard, privacy, opensource, fully"
"People here say they use local LLMs for story telling, chat, etc., but what ""stories"" are they telling and in what applications? I imagine just building a PC rig to have a story-telling LLM is overkill. Am I missing something? Please let us know if you're using LLMs in a creative way!",Topic 2,"llm, model, llama, local, mistral, etc, use, cloud, generative, language"
Can Agent-to-Agent communication be encrypted by said agents (not available to humans)?,Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
Looking for the best cost/price mini(?)-pc for a local llm,Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
"Besides curiosity, what do you use local LLMs for?",Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
🖥️🔮 Future Hardware Options for LLMs: Nvidia vs. Apple?,Topic 7,"llm, local, ui, better, v, docker, rag, ollama, web, two"
Home LLM. Why?,Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
"WikiChat: Stopping the Hallucination of Large Language Model Chatbots by Few-Shot Grounding on Wikipedia - Achieves 97.9% factual accuracy in conversations with human users about recent topics, 55.0% better than GPT-4! - Stanford University 2023",Topic 0,"v, gpt, ai, model, test, security, gemini, using, uncensored, showdown"
"Local LLM to learn, explore and use for commercial purpose",Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
Need advice on Strategys for Local Hosting,Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
What do you use local LLMs for? This time with examples.,Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
I'm convinced now that “personal LLMs” are going to be a huge thing,Topic 7,"llm, local, ui, better, v, docker, rag, ollama, web, two"
"Dumb question, perhaps. How do I enable internet access for a locally run AI?",Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
Why LocalLLaMa when GPT-4 exists?,Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
"What percent of your usage of LLMs are closed-source ones (GPT, Claude, etc.) and what percent are open source ones (Llama, Mistral, etc.)? Pick the answer that's closest to you.",Topic 2,"llm, model, llama, local, mistral, etc, use, cloud, generative, language"
"Nearing Q4 23, what's the best web UI frontend?",Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
Any other fun local AI tools other than ooba and automatic1111?,Topic 0,"v, gpt, ai, model, test, security, gemini, using, uncensored, showdown"
What's the best way to beat GPT-5 with Open Source & Distributed Compute?,Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
"Llama2 is in practice much worse than ChatGPT, isn't it ?",Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
"A .gguf chatbot gradio interface experiment, to sequentially chain prompts, scripted in csv file : gpt-sequencer",Topic 9,"llm, run, model, using, time, locally, local, gpu, prompt, ram"
"EU Parliament approved the text of the AI Regulation Law (it is not applied yet, but we might be very near) - Which models should I hoard? Which are the best uncensored before the blackout?",Topic 0,"v, gpt, ai, model, test, security, gemini, using, uncensored, showdown"
What's your main interest in running a local LLM instead of using an existing API?,Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
From a production standpoint which makes local LLM a better option?,Topic 8,"local, llm, order, executive, running, v, wizard, privacy, opensource, fully"
Ollama cost-effectiveness versus OpenAI,Topic 4,"ai, llm, running, data, comparing, llama, gpus, need, privacy, fine"
How do you compare 100s of documents with a local LLM?,Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
How have local LLMs helped your business?,Topic 8,"local, llm, order, executive, running, v, wizard, privacy, opensource, fully"
Has anyone here done quant method benchmarking?,Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
Advice on Open source LLM for pdf query aka Retrieval Augmented Generation,Topic 9,"llm, run, model, using, time, locally, local, gpu, prompt, ram"
Best french model & stack for 3.5gpt like experience,Topic 1,"model, code, training, llm, data, question, finetuning, set, best, experience"
LLM for audit logs,Topic 9,"llm, run, model, using, time, locally, local, gpu, prompt, ram"
Finetuning Chat LLM (Llama2-chat): Data set best practices,Topic 1,"model, code, training, llm, data, question, finetuning, set, best, experience"
Best LLM for legal analysis,Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
"CodeLLama 70B pontificates on ethics where 13B and 7B ""just do it""",Topic 0,"v, gpt, ai, model, test, security, gemini, using, uncensored, showdown"
What are your suggestions on hosting LLama2 for an enterprise? [commercial],Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
LLM that answers questions based on documents,Topic 1,"model, code, training, llm, data, question, finetuning, set, best, experience"
Any open source prompt Enhancing LLM projects?,Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
"Newbie here, what laptop specs do I need to run more capable AIs ?",Topic 8,"local, llm, order, executive, running, v, wizard, privacy, opensource, fully"
Multi-Client model Fine-tuning: One model or individual models for each client?,Topic 1,"model, code, training, llm, data, question, finetuning, set, best, experience"
Seeking Assistance: Anonymized Datasets of Therapeutic Conversations,Topic 7,"llm, local, ui, better, v, docker, rag, ollama, web, two"
My first real life test Gemini vs GPT-4. Am I surprised or shocked? :),Topic 0,"v, gpt, ai, model, test, security, gemini, using, uncensored, showdown"
Why run LLMs locally?,Topic 9,"llm, run, model, using, time, locally, local, gpu, prompt, ram"
What attracted you to local LLMs?,Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
Best option to get a model to answer question on a lot of selected book.,Topic 1,"model, code, training, llm, data, question, finetuning, set, best, experience"
LVE Project: First Open Source Repository of LLM Vulnerabilities,Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
What do you use your local llama for?,Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
Using local models for qualitative analysis,Topic 2,"llm, model, llama, local, mistral, etc, use, cloud, generative, language"
Addressing the Elephant in the Room,Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
Are there any models recommended for legal writing?,Topic 2,"llm, model, llama, local, mistral, etc, use, cloud, generative, language"
Mac Config vs Dual Machines,Topic 8,"local, llm, order, executive, running, v, wizard, privacy, opensource, fully"
Mac users with Apple Silicon and 8GB ram - use GPT4all,Topic 2,"llm, model, llama, local, mistral, etc, use, cloud, generative, language"
"🚀 Completely Local RAG with Ollama Web UI, in Two Docker Commands!",Topic 7,"llm, local, ui, better, v, docker, rag, ollama, web, two"
A Review: Using Llama 2 to Chat with Notes on Consumer Hardware,Topic 0,"v, gpt, ai, model, test, security, gemini, using, uncensored, showdown"
LLM trained on code memorizes 8% of the training set and could expose code used for training,Topic 1,"model, code, training, llm, data, question, finetuning, set, best, experience"
Question about multiple sources with vector embeddings & local LLM.,Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
LM Studio v0.2.11 Update Significantly Speeds Up Inference Running Server,Topic 4,"ai, llm, running, data, comparing, llama, gpus, need, privacy, fine"
Fine Tuning Style into LLMs,Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
Can I train Llama with my own PDF documents?,Topic 4,"ai, llm, running, data, comparing, llama, gpus, need, privacy, fine"
Model suggestions for coding + workflow?,Topic 1,"model, code, training, llm, data, question, finetuning, set, best, experience"
On RP and lore,Topic 7,"llm, local, ui, better, v, docker, rag, ollama, web, two"
Seeking Advice: Building a High-Performance PC for AI Inference and Gaming,Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
Local LLama vs other GPT local alternatives (like gpt4all),Topic 0,"v, gpt, ai, model, test, security, gemini, using, uncensored, showdown"
Local VS Cloud?,Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
LLMs in the middle: Content-aware browser filters for social media,Topic 7,"llm, local, ui, better, v, docker, rag, ollama, web, two"
My experience on starting with fine tuning LLMs with custom data,Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
Google Cloud partners with Mistral AI on generative language models,Topic 2,"llm, model, llama, local, mistral, etc, use, cloud, generative, language"
Which model to use and which fine tuning to chat with a mail archive of 15 years?,Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
Local LLM chat agent with advanced RAG and memory,Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
Llm Super Coach - Small fun project to use a local LLM to analyze one's diaries in various ways.,Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
What are you favorite usecases / examples for CFG (classifier free guidance)?,Topic 2,"llm, model, llama, local, mistral, etc, use, cloud, generative, language"
"Currently, what are the practical applications of local language models?",Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
Advantage of Local vs GPT4 for use case? Generating text in specific style based on examples,Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
Method to block possible internet traffic from LLaMA on MacOS,Topic 2,"llm, model, llama, local, mistral, etc, use, cloud, generative, language"
Short guide to hosting your own llama.cpp openAI compatible web-server,Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
7B models use with Langchainn for Chatbox importing of txt or pdf's,Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
"AgentOoba v0.1 - better UI, better contextualization, the beginnings of langchain integration and tools",Topic 7,"llm, local, ui, better, v, docker, rag, ollama, web, two"
Self-hosted LLama2 in AI Code Assistant : Refact,Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
I wish there was a market for buying access to proprietary LLMs to run locally,Topic 9,"llm, run, model, using, time, locally, local, gpu, prompt, ram"
Fine-Tuning Language Models with Just Forward Passes,Topic 1,"model, code, training, llm, data, question, finetuning, set, best, experience"
Best open source LLM model for commercial use,Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
Here is Gemini Advanced struggling with the famous Sally riddle,Topic 0,"v, gpt, ai, model, test, security, gemini, using, uncensored, showdown"
Validity of metrics,Topic 4,"ai, llm, running, data, comparing, llama, gpus, need, privacy, fine"
Best approach to local LLMs for a journal?,Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
"Thanks everyone for help, currently i use what can i use",Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
Fine-tuned llama2-7b-lora vs chatGPT in a noble game of chess?,Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
played some d&d with openhermes-2-mistral-7b then broke the 3rd wall,Topic 4,"ai, llm, running, data, comparing, llama, gpus, need, privacy, fine"
Help with LLM Stable Diffusion Prompt Generator,Topic 9,"llm, run, model, using, time, locally, local, gpu, prompt, ram"
HuggingChatAllInOne: Run HF and GPTQ models using HuggingChat UI easily,Topic 9,"llm, run, model, using, time, locally, local, gpu, prompt, ram"
🐺🐦‍⬛ LLM Comparison/Test: API Edition (GPT-4 vs. Gemini vs. Mistral vs. local LLMs),Topic 0,"v, gpt, ai, model, test, security, gemini, using, uncensored, showdown"
"""Successful"" Run of pygmalion-1.3b.q4_1 on 4gb Ram Acer Windows 10 Laptop",Topic 9,"llm, run, model, using, time, locally, local, gpu, prompt, ram"
"Adding keywords related to topic to LLM context improves performance, here's my prompt to generate them and some keywords for being a machine-learning engineer.",Topic 6,"local, use, model, llama, llm, keywords, ai, v, context, new"
What prompts can be used for text classification with LLMs,Topic 3,"llm, local, best, way, tuning, fine, gpt, use, model, question"
Analysis: Mixtral 34Bx2 MoE 60B vs. Copilot (GPT4) for in-context learning (chain-of-thought),Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
The travelling LLaMa: Graph theory meets local LLM - another test of performance of local LLMs,Topic 5,"llm, local, open, source, v, commercial, agent, project, hosting, ai"
Comparing StableLM Tuned 7B and Vicuna 7B,Topic 4,"ai, llm, running, data, comparing, llama, gpus, need, privacy, fine"
